{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "DQN_project_Thomas Fauré.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zc2U7Nx6jY_i",
        "colab_type": "text"
      },
      "source": [
        "**You may need to install [OpenCV](https://pypi.python.org/pypi/opencv-python) and [scikit-video](http://www.scikit-video.org/stable/).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUazKIQrjY_k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "fbb04840-6ac8-4513-8e58-f313be74604c"
      },
      "source": [
        "import tensorflow.keras\n",
        "import numpy as np\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqg9eREwDpeD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fd98734a-5c47-4605-a5a4-b87e2724f612"
      },
      "source": [
        " pip install opencv-python"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.17.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "echvfqa5jY_n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "d4cb0d04-1de8-4846-e7ab-cf3586ee9230"
      },
      "source": [
        "pip install scikit-video"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-video\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/a6/c69cad508139a342810ae46e946ebb3256aa6e42f690d901bb68f50582e3/scikit_video-1.1.11-py2.py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from scikit-video) (6.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from scikit-video) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from scikit-video) (1.17.5)\n",
            "Installing collected packages: scikit-video\n",
            "Successfully installed scikit-video-1.1.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxPq7TMSjY_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import skvideo\n",
        "#skvideo.setFFmpegPath(\"/Users/thomasfaure/Downloads/ffmpeg-20200129-de1b2aa-macos64-static/bin\")\n",
        "import skvideo.io"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0AocOQKjY_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbz2WsVRjY_w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "21901cc5-74be-410a-cfd2-29c83ea75463"
      },
      "source": [
        "pip install keras"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.17.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESv7Ke7XjY_z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e8e979d4-513b-4f83-9a4b-d0bad2ade728"
      },
      "source": [
        "import json\n",
        "\n",
        "\n",
        "from tensorflow.keras import backend\n",
        "\n",
        "from tensorflow.keras.models import Sequential,model_from_json\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import sgd, adam\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D,Reshape,BatchNormalization, Flatten\n",
        "\n",
        "\n",
        "from keras.models import Sequential,model_from_json\n",
        "from keras.layers.core import Dense, Flatten\n",
        "from keras.optimizers import sgd\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D,Reshape,BatchNormalization"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkrN5RuRjY_1",
        "colab_type": "text"
      },
      "source": [
        "# MiniProject on Deep Reinforcement Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxE_ComJjY_2",
        "colab_type": "text"
      },
      "source": [
        "__Notations__: $E_p$ is the expectation under probability $p$. Please justify each of your answer and widely comment your code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmqolD2jjY_3",
        "colab_type": "text"
      },
      "source": [
        "# Context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_Pz8lSSjY_4",
        "colab_type": "text"
      },
      "source": [
        "In a reinforcement learning algorithm, we modelize each step $t$ as an action $a_t$ obtained from a state $s_t$, i.e. $\\{(a_{t},s_{t})_{t\\leq T}\\}$ having the Markov property. We consider a discount factor $\\gamma \\in [0,1]$ that ensures convergence. The goal is to find among all the policies $\\pi$, one that maximizes the expected reward:\n",
        "\n",
        "\\begin{equation*}\n",
        "R(\\pi)=\\sum_{t\\leq T}E_{p^{\\pi}}[\\gamma^t r(s_{t},a_{t})] \\> ,\n",
        "\\end{equation*}\n",
        "\n",
        "where: \n",
        "\\begin{equation*}p^{\\pi}(a_{0},a_{1},s_{1},...,a_{T},s_{T})=p(a_{0})\\prod_{t=1}^{T}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "We note the $Q$-function:\n",
        "\n",
        "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "Thus, the optimal Q function is:\n",
        "\\begin{equation*}\n",
        "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "In this project, we will apply the deep reinforcement learning techniques to a simple game: an agent will have to learn from scratch a policy that will permit it maximizing a reward."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScVtUTDCjY_4",
        "colab_type": "text"
      },
      "source": [
        "## The environment, the agent and the game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4LduViRjY_5",
        "colab_type": "text"
      },
      "source": [
        "### The environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K47Pn2o0jY_6",
        "colab_type": "text"
      },
      "source": [
        "```Environment``` is an abstract class that represents the states, rewards, and actions to obtain the new state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLJisGUwjY_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Environment(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def act(self, act):\n",
        "        \"\"\"\n",
        "        One can act on the environment and obtain its reaction:\n",
        "        - the new state\n",
        "        - the reward of the new state\n",
        "        - should we continue the game?\n",
        "\n",
        "        :return: state, reward, game_over\n",
        "        \"\"\"\n",
        "        #state , reward , game_over , info = env.step(act)\n",
        "        #return state , reward , game_over\n",
        "        pass\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Reinitialize the environment to a random state and returns\n",
        "        the original state\n",
        "\n",
        "        :return: state\n",
        "        \"\"\"\n",
        "        #state = env.reset()\n",
        "        #return state\n",
        "        pass\n",
        "    \n",
        "    def draw(self):\n",
        "        \"\"\"\n",
        "        Visualize in the console or graphically the current state\n",
        "        \"\"\"\n",
        "        #print(env.render())\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-MHskwqjY_9",
        "colab_type": "text"
      },
      "source": [
        "The method ```act``` allows to act on the environment at a given state $s_t$ (stored internally), via action $a_t$. The method will return the new state $s_{t+1}$, the reward $r(s_{t},a_{t})$ and determines if $t\\leq T$ (*game_over*).\n",
        "\n",
        "The method ```reset``` simply reinitializes the environment to a random state $s_0$.\n",
        "\n",
        "The method ```draw``` displays the current state $s_t$ (this is useful to check the behavior of the Agent).\n",
        "\n",
        "We modelize $s_t$ as a tensor, while $a_t$ is an integer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeTzp6wbjY_-",
        "colab_type": "text"
      },
      "source": [
        "### The Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tz54dkK6jY__",
        "colab_type": "text"
      },
      "source": [
        "The goal of the ```Agent``` is to interact with the ```Environment``` by proposing actions $a_t$ obtained from a given state $s_t$ to attempt to maximize its __reward__ $r(s_t,a_t)$. We propose the following abstract class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBdSvVjvjY__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Agent(object):\n",
        "    def __init__(self, epsilon=0.1, n_action=4):\n",
        "        self.epsilon = epsilon\n",
        "        self.n_action = n_action\n",
        "    \n",
        "    def set_epsilon(self,e):\n",
        "        self.epsilon = e\n",
        "\n",
        "    def act(self,s,train=True):\n",
        "        \"\"\" This function should return the next action to do:\n",
        "        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
        "        if train:\n",
        "            if np.random.rand() <= self.epsilon:\n",
        "                a = np.random.randint(0, self.n_action, size=1)[0]\n",
        "            else:\n",
        "                a = self.learned_act(s)\n",
        "        else: # in some cases, this can improve the performance.. remove it if poor performances\n",
        "            a = self.learned_act(s)\n",
        "\n",
        "        return a\n",
        "\n",
        "    def learned_act(self,s):\n",
        "        \"\"\" Act via the policy of the agent, from a given state s\n",
        "        it proposes an action a\"\"\"\n",
        "        pass\n",
        "\n",
        "    def reinforce(self, s, n_s, a, r, game_over_):\n",
        "        \"\"\" This function is the core of the learning algorithm. \n",
        "        It takes as an input the current state s_, the next state n_s_\n",
        "        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
        "        \n",
        "        Its goal is to learn a policy.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def save(self):\n",
        "        \"\"\" This function returns basic stats if applicable: the\n",
        "        loss and/or the model\"\"\"\n",
        "        pass\n",
        "\n",
        "    def load(self):\n",
        "        \"\"\" This function allows to restore a model\"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PHnRyMojZAB",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 1__:\n",
        "Explain the function act. Why is ```epsilon``` essential?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rkk_zpNUjZAC",
        "colab_type": "text"
      },
      "source": [
        "Act is supposed to give the agent the next action to do according to a current state, i.e. where the agent is right now. We introduce an epsilon to deal with the exploration and exploitation dilemma. We want our agent to learn a policy so he needs to visit all the state in order to know what to do in each situation (exploration) but we want him to learn the best policy so we need to encourage him to exploit the states he has visited (exploitation). A large epsilon means a lot of exploration while a small one means a lot of exploitation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrpbXY8WjZAD",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "### The Game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBLeTO64jZAD",
        "colab_type": "text"
      },
      "source": [
        "The ```Agent``` and the ```Environment``` work in an interlaced way as in the following (take some time to understand this code as it is the core of the project)\n",
        "\n",
        "```python\n",
        "\n",
        "epoch = 300\n",
        "env = Environment()\n",
        "agent = Agent()\n",
        "\n",
        "\n",
        "# Number of won games\n",
        "score = 0\n",
        "loss = 0\n",
        "\n",
        "\n",
        "for e in range(epoch):\n",
        "    # At each epoch, we restart to a fresh game and get the initial state\n",
        "    state = env.reset()\n",
        "    # This assumes that the games will end\n",
        "    game_over = False\n",
        "\n",
        "    win = 0\n",
        "    lose = 0\n",
        "    \n",
        "    while not game_over:\n",
        "        # The agent performs an action\n",
        "        action = agent.act(state)\n",
        "\n",
        "        # Apply an action to the environment, get the next state, the reward\n",
        "        # and if the games end\n",
        "        prev_state = state\n",
        "        state, reward, game_over = env.act(action)\n",
        "\n",
        "        # Update the counters\n",
        "        if reward > 0:\n",
        "            win = win + reward\n",
        "        if reward < 0:\n",
        "            lose = lose -reward\n",
        "\n",
        "        # Apply the reinforcement strategy\n",
        "        loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "    # Save as a mp4\n",
        "    if e % 10 == 0:\n",
        "        env.draw(e)\n",
        "\n",
        "    # Update stats\n",
        "    score += win-lose\n",
        "\n",
        "    print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "          .format(e, epoch, loss, win, lose, win-lose))\n",
        "    agent.save()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CV3TFij-jZAE",
        "colab_type": "text"
      },
      "source": [
        "# The game, *eat cheese*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUrentmXjZAF",
        "colab_type": "text"
      },
      "source": [
        "A rat runs on an island and tries to eat as much as possible. The island is subdivided into $N\\times N$ cells, in which there are cheese (+0.5) and poisonous cells (-1). The rat has a visibility of 2 cells (thus it can see $5^2$ cells). The rat is given a time $T$ to accumulate as much food as possible. It can perform 4 actions: going up, down, left, right. \n",
        "\n",
        "The goal is to code an agent to solve this task that will learn by trial and error. We propose the following environment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7IFSxtLjZAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Environment(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        grid_size = grid_size+4\n",
        "        self.grid_size = grid_size\n",
        "        self.max_time = max_time\n",
        "        self.temperature = temperature\n",
        "\n",
        "        #board on which one plays\n",
        "        self.board = np.zeros((grid_size,grid_size))\n",
        "        self.position = np.zeros((grid_size,grid_size))\n",
        "\n",
        "        # coordinate of the cat\n",
        "        self.x = 0\n",
        "        self.y = 1\n",
        "\n",
        "        # self time\n",
        "        self.t = 0\n",
        "\n",
        "        self.scale=16\n",
        "\n",
        "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "    def draw(self,e):\n",
        "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
        "\n",
        "    def get_frame(self,t):\n",
        "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
        "        b[self.board>0,0] = 256\n",
        "        b[self.board < 0, 2] = 256\n",
        "        b[self.x,self.y,:]=256\n",
        "        b[-2:,:,:]=0\n",
        "        b[:,-2:,:]=0\n",
        "        b[:2,:,:]=0\n",
        "        b[:,:2,:]=0\n",
        "        \n",
        "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        self.to_draw[t,:,:,:]=b\n",
        "\n",
        "\n",
        "    def act(self, action):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        #self.position[-2:, :] = -1\n",
        "        self.position[:, -2:] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0:\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "\n",
        "        self.t = self.t + 1\n",
        "        reward = self.board[self.x, self.y]\n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "\n",
        "        return state, reward, game_over\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        #self.position[-2:, :] = -1\n",
        "        self.position[:, -2:] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "        self.t = 0\n",
        "\n",
        "        state = np.concatenate((\n",
        "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XabxujYLjZAH",
        "colab_type": "text"
      },
      "source": [
        "The following elements are important because they correspond to the hyper parameters for this project:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipE82_lHjZAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# parameters\n",
        "size = 13\n",
        "T=200\n",
        "temperature=0.3\n",
        "epochs_train=20 # set small when debugging\n",
        "epochs_test=20 # set small when debugging\n",
        "\n",
        "# display videos\n",
        "def display_videos(name):\n",
        "    video = io.open(name, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    return '''<video alt=\"test\" controls>\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36OZWuw9jZAN",
        "colab_type": "text"
      },
      "source": [
        "__Question 2__ Explain the use of the arrays ```position``` and ```board```."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkD_ubG4jZAO",
        "colab_type": "text"
      },
      "source": [
        "Position is a matrix with a 1 on the current position of the rat, -1 where he cannot go and 0 otherwise\n",
        "\n",
        "\n",
        "Board represents the reward of the cells."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZ_697xGjZAO",
        "colab_type": "text"
      },
      "source": [
        "## Random Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hb4IsIBHjZAP",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 3__ Implement a random Agent (only ```learned_act``` needs to be implemented):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpWFe9CpjZAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RandomAgent(Agent):\n",
        "    def __init__(self):\n",
        "        super(RandomAgent, self).__init__()\n",
        "        pass\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        action = np.random.randint(0, self.n_action, size=1)[0]\n",
        "        return action"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBQv52qBjZAR",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 4__ Visualize the game moves. You need to fill in the following function for the evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN-NzSrijZAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(agent,env,epochs,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "        \n",
        "    for e in range(epochs):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        \n",
        "        # This assumes that the games will end\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "        \n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state, train = False)\n",
        "        \n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        "            \n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "        \n",
        "        \n",
        "        # Save as a mp4\n",
        "        if e % 5 == 0:\n",
        "            env.draw(prefix + str(e))\n",
        "        #env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score = score + win-lose\n",
        "\n",
        "        print(\"Win/lose count {}/{}. Average score ({})\"\n",
        "              .format(win, lose, score/(1+e)))\n",
        "    print('Final score: '+str(score/epochs))\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIfejs4BjZAU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "outputId": "ff2d564b-9686-4de0-922b-a182d47e9744"
      },
      "source": [
        "# Initialize the game\n",
        "env = Environment(grid_size=size, max_time=T,temperature=temperature)\n",
        "\n",
        "# Initialize the agent!\n",
        "agent = RandomAgent()\n",
        "\n",
        "test(agent,env,epochs_test,prefix='random')\n",
        "HTML(display_videos('random0.mp4'))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 14.5/16.0. Average score (-1.5)\n",
            "Win/lose count 11.0/14.0. Average score (-2.25)\n",
            "Win/lose count 11.0/11.0. Average score (-1.5)\n",
            "Win/lose count 7.0/11.0. Average score (-2.125)\n",
            "Win/lose count 11.0/12.0. Average score (-1.9)\n",
            "Win/lose count 7.5/15.0. Average score (-2.8333333333333335)\n",
            "Win/lose count 12.5/15.0. Average score (-2.7857142857142856)\n",
            "Win/lose count 10.5/16.0. Average score (-3.125)\n",
            "Win/lose count 9.5/13.0. Average score (-3.1666666666666665)\n",
            "Win/lose count 14.0/13.0. Average score (-2.75)\n",
            "Win/lose count 12.0/12.0. Average score (-2.5)\n",
            "Win/lose count 6.5/8.0. Average score (-2.4166666666666665)\n",
            "Win/lose count 7.5/18.0. Average score (-3.0384615384615383)\n",
            "Win/lose count 8.0/16.0. Average score (-3.392857142857143)\n",
            "Win/lose count 8.0/9.0. Average score (-3.2333333333333334)\n",
            "Win/lose count 9.5/14.0. Average score (-3.3125)\n",
            "Win/lose count 9.5/15.0. Average score (-3.4411764705882355)\n",
            "Win/lose count 10.0/14.0. Average score (-3.4722222222222223)\n",
            "Win/lose count 8.0/11.0. Average score (-3.4473684210526314)\n",
            "Win/lose count 9.0/14.0. Average score (-3.525)\n",
            "Final score: -3.525\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcIDF_xAjZAX",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "## DQN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikvG1cyKjZAY",
        "colab_type": "text"
      },
      "source": [
        "Let us assume here that $T=\\infty$.\n",
        "\n",
        "***\n",
        "__Question 5__ Let $\\pi$ be a policy, show that:\n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
        "\\end{equation*}\n",
        "\n",
        "Then, show that for the optimal policy $\\pi^*$ (we assume its existence), the following holds: \n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
        "\\end{equation*}\n",
        "Finally, deduce that a plausible objective is:\n",
        "\n",
        "\\begin{equation*}\n",
        "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
        "\\end{equation*}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF4BZQH7jZAY",
        "colab_type": "text"
      },
      "source": [
        "Question 1\n",
        "\n",
        "$$\n",
        "Q^{\\pi}(s,a) = E_{p^\\pi}[\\sum_{t\\leq T} \\gamma^{t} r(s_t,a_t)|s_0 = s, a_0 = a]\\\\\n",
        "= E_{p^\\pi}[  r(s,a) + \\gamma\\sum_{t=1}^{T} \\gamma^{t-1} r(s_t,a_t)|s_0 = s, a_0 = a]\\\\\n",
        "= r(s,a) + \\gamma \\sum_{s'}\\sum_{a'}p(s_1 = s',a_1 = a'|s_0 = s, a_0 = a)E[\\sum_{t=1}^{T}\\gamma^{t-1}r(s_t,a_t)|s_1 = s', a_1 = a']\\\\\n",
        "= r(s,a) + \\gamma\\sum_{s'}\\sum_{a'}p(s',a'|s_0 = s, a_0 = a)Q^{\\pi}(s',a')\\\\\n",
        "=r(s,a) + \\gamma E_{s',a'\\sim p(.|s,a)}[Q^{\\pi}(s',a')]\n",
        "$$\n",
        "\n",
        "Question 2 \n",
        "\n",
        "$$\n",
        "Q^{*}(s,a) = \\max_{\\pi}E_{p^\\pi}[\\sum_{t\\leq T} \\gamma^{t} r(s_t,a_t)|s_0 = s, a_0 = a]\\\\\n",
        "= \\max_{\\pi'} ( r(s,a) + \\gamma \\sum_{s'}\\sum_{a'}p(s',a'|s_0 = s, a_0 = a)Q^{\\pi'}(s',a')) \\\\\n",
        "= r(s,a) + \\gamma \\sum_{s'}\\sum_{a'}p(s',a'|s_0 = s, a_0 = a)\\max_{\\pi'}Q^{\\pi'}(s',a') \\\\\n",
        "= r(s,a) + \\gamma \\sum_{s'}\\sum_{a'}p(s',a'|s_0 = s, a_0 = a)Q^{*}(s',a') \\\\\n",
        "= E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')]\n",
        "$$\n",
        "\n",
        "Queston 3\n",
        "\n",
        "We can recognize the mean square error \n",
        "$$\n",
        "\\mathcal{L}(\\theta)= E[(\\hat{\\theta} - \\theta)^{2}]\\\\\n",
        "E_{s' \\sim \\pi^*(.|s,a)}[\\Vert Q^{*}(s,a,\\theta^{*})-Q(s,a,\\theta)\\Vert^{2}\\Vert^{2}]\\\\\n",
        "E_{s' \\sim \\pi^*(.|s,a)}[\\Vert r+\\gamma\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}]\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjfW1aUDjZAZ",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "The DQN-learning algorithm relies on these derivations to train the parameters $\\theta$ of a Deep Neural Network:\n",
        "\n",
        "1. At the state $s_t$, select the action $a_t$ with best reward using $Q_t$ and store the results;\n",
        "\n",
        "2. Obtain the new state $s_{t+1}$ from the environment $p$;\n",
        "\n",
        "3. Store $(s_t,a_t,s_{t+1})$;\n",
        "\n",
        "4. Obtain $Q_{t+1}$ by minimizing  $\\mathcal{L}$ from a recovered batch from the previously stored results.\n",
        "\n",
        "***\n",
        "__Question 6__ Implement the class ```Memory``` that stores moves (in a replay buffer) via ```remember``` and provides a ```random_access``` to these. Specify a maximum memory size to avoid side effects. You can for example use a ```list()``` and set by default ```max_memory=100```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISEJjLbljZAZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Memory(object):\n",
        "    def __init__(self, max_memory=100):\n",
        "        self.max_memory = max_memory\n",
        "        self.memory = list()\n",
        "\n",
        "    def remember(self, m):\n",
        "        self.memory.append(m)\n",
        "        if len(self.memory) > self.max_memory:\n",
        "            del self.memory[0]\n",
        "\n",
        "    def random_access(self):\n",
        "        i = np.random.choice(len(self.memory))\n",
        "        return self.memory[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9CoLUK_jZAc",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "The pipeline we will use for training is given below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFHk_eb3jZAc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(agent,env,epoch,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "\n",
        "    for e in range(epoch):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1fF_Rg6jZAe",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 7__ Implement the DQN training algorithm using a cascade of fully connected layers. You can use different learning rate, batch size or memory size parameters. In particular, the loss might oscillate while the player will start to win the games. You have to find a good criterium."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t90QA2jfjZAe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN(Agent):\n",
        "    def __init__(self, grid_size,  epsilon = 0.1, memory_size=100, batch_size = 16,n_state=2):\n",
        "        super(DQN, self).__init__(epsilon = epsilon)\n",
        "\n",
        "        # Discount for Q learning\n",
        "        self.discount = 0.99\n",
        "        \n",
        "        self.grid_size = grid_size\n",
        "        \n",
        "        # number of state\n",
        "        self.n_state = n_state\n",
        "\n",
        "        # Memory\n",
        "        self.memory = Memory(memory_size)\n",
        "        \n",
        "        # Batch size when learning\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        s = np.expand_dims(s,axis=0)\n",
        "        action = np.argmax(self.model.predict(s))\n",
        "        return action\n",
        "\n",
        "    def reinforce(self, s_, n_s_, a_, r_, game_over_):\n",
        "        # Two steps: first memorize the states, second learn from the pool\n",
        "\n",
        "        self.memory.remember([s_, n_s_, a_, r_, game_over_])\n",
        "        \n",
        "        input_states = np.zeros((self.batch_size, 5,5,self.n_state))\n",
        "        target_q = np.zeros((self.batch_size, 4))\n",
        "        \n",
        "        for i in range(self.batch_size):\n",
        "            \n",
        "            state, next_state, action, reward, game_over = self.memory.random_access()\n",
        "            target_q[i] = self.model.predict(np.expand_dims(state, axis = 0))\n",
        "            input_states[i,:,:,:] = state\n",
        "            next_state = np.expand_dims(next_state, axis = 0)  \n",
        "            \n",
        "            if game_over_:\n",
        "                target_q[i,action] = reward\n",
        "                \n",
        "            else:\n",
        "                target_q[i,action] = reward + self.discount*np.max(self.model.predict(next_state))\n",
        "        \n",
        "        \n",
        "        # HINT: Clip the target to avoid exploiding gradients.. -- clipping is a bit tighter\n",
        "        target_q = np.clip(target_q, -3, 3)\n",
        "\n",
        "        l = self.model.train_on_batch(input_states, target_q)\n",
        "\n",
        "\n",
        "        return l\n",
        "\n",
        "    def save(self,name_weights='model.h5',name_model='model.json'):\n",
        "        self.model.save_weights(name_weights, overwrite=True)\n",
        "        with open(name_model, \"w\") as outfile:\n",
        "            json.dump(self.model.to_json(), outfile)\n",
        "            \n",
        "    def load(self,name_weights='model.h5',name_model='model.json'):\n",
        "        with open(name_model, \"r\") as jfile:\n",
        "            model = model_from_json(json.load(jfile))\n",
        "        model.load_weights(name_weights)\n",
        "        model.compile(\"sgd\", \"mse\")\n",
        "        self.model = model\n",
        "\n",
        "            \n",
        "class DQN_FC(DQN):\n",
        "    def __init__(self, *args, lr=0.1,**kwargs):\n",
        "        super(DQN_FC, self).__init__( *args,**kwargs)\n",
        "        \n",
        "        # NN Model\n",
        "        model = Sequential()\n",
        "        model.add(Flatten(input_shape=(5,5,self.n_state,)))\n",
        "        model.add(Dense(25,activation ='relu'))\n",
        "        model.add(Dense(4))\n",
        "        \n",
        "        model.compile(adam(lr=lr, decay=1e-4), \"mse\")\n",
        "        self.model = model\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TBy0KmdjZAh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e11eedf1-3dcc-4f23-efb4-58a4c38f2ef7"
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_FC(size, lr=.001, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "train(agent, env, epochs_train, prefix='fc_train')\n",
        "HTML(display_videos('fc_train10.mp4'))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 000/020 | Loss 0.0276 | Win/lose count 3.0/9.0 (-6.0)\n",
            "Epoch 001/020 | Loss 0.3337 | Win/lose count 2.0/5.0 (-3.0)\n",
            "Epoch 002/020 | Loss 0.8553 | Win/lose count 5.5/4.0 (1.5)\n",
            "Epoch 003/020 | Loss 1.4006 | Win/lose count 3.0/0 (3.0)\n",
            "Epoch 004/020 | Loss 1.6518 | Win/lose count 4.5/6.0 (-1.5)\n",
            "Epoch 005/020 | Loss 1.8211 | Win/lose count 2.0/3.0 (-1.0)\n",
            "Epoch 006/020 | Loss 1.8302 | Win/lose count 6.5/3.0 (3.5)\n",
            "Epoch 007/020 | Loss 1.8998 | Win/lose count 6.0/6.0 (0.0)\n",
            "Epoch 008/020 | Loss 1.9249 | Win/lose count 6.5/1.0 (5.5)\n",
            "Epoch 009/020 | Loss 2.0255 | Win/lose count 9.0/2.0 (7.0)\n",
            "Epoch 010/020 | Loss 1.9661 | Win/lose count 5.0/2.0 (3.0)\n",
            "Epoch 011/020 | Loss 1.9610 | Win/lose count 4.0/1.0 (3.0)\n",
            "Epoch 012/020 | Loss 1.9126 | Win/lose count 4.0/2.0 (2.0)\n",
            "Epoch 013/020 | Loss 1.8506 | Win/lose count 2.5/0 (2.5)\n",
            "Epoch 014/020 | Loss 1.8337 | Win/lose count 3.5/2.0 (1.5)\n",
            "Epoch 015/020 | Loss 1.8151 | Win/lose count 3.0/5.0 (-2.0)\n",
            "Epoch 016/020 | Loss 1.8454 | Win/lose count 3.5/2.0 (1.5)\n",
            "Epoch 017/020 | Loss 1.9296 | Win/lose count 6.0/3.0 (3.0)\n",
            "Epoch 018/020 | Loss 1.7197 | Win/lose count 5.5/8.0 (-2.5)\n",
            "Epoch 019/020 | Loss 1.6815 | Win/lose count 5.0/4.0 (1.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KMUKH8ijZAi",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 8__ Implement the DQN training algorithm using a CNN (for example, 2 convolutional layers and one final fully connected layer)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4aMkkRZjZAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN_CNN(DQN):\n",
        "    def __init__(self, *args,lr=0.1,**kwargs):\n",
        "        super(DQN_CNN, self).__init__(*args,**kwargs)\n",
        "        \n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(50, (2,2), input_shape=(5,5, self.n_state), activation='relu'))\n",
        "        model.add(Conv2D(30, (2,2), activation = 'relu'))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4))\n",
        "        \n",
        "        model.compile(adam(lr=lr, decay=1e-4), \"mse\")\n",
        "        self.model = model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2c4piD9jZAl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "outputId": "81909186-b03e-4611-d4f2-ae52e6975bec"
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_CNN(size, lr=.001, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "train(agent,env,epochs_train,prefix='cnn_train')\n",
        "HTML(display_videos('cnn_train10.mp4'))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000/020 | Loss 1.8320 | Win/lose count 3.5/9.0 (-5.5)\n",
            "Epoch 001/020 | Loss 2.1869 | Win/lose count 3.0/5.0 (-2.0)\n",
            "Epoch 002/020 | Loss 1.0286 | Win/lose count 0/1.0 (-1.0)\n",
            "Epoch 003/020 | Loss 1.9937 | Win/lose count 5.5/0 (5.5)\n",
            "Epoch 004/020 | Loss 1.9813 | Win/lose count 3.0/0 (3.0)\n",
            "Epoch 005/020 | Loss 1.9002 | Win/lose count 6.5/4.0 (2.5)\n",
            "Epoch 006/020 | Loss 1.9417 | Win/lose count 4.5/7.0 (-2.5)\n",
            "Epoch 007/020 | Loss 1.8660 | Win/lose count 4.5/2.0 (2.5)\n",
            "Epoch 008/020 | Loss 1.8798 | Win/lose count 4.0/2.0 (2.0)\n",
            "Epoch 009/020 | Loss 1.7677 | Win/lose count 8.5/1.0 (7.5)\n",
            "Epoch 010/020 | Loss 1.7447 | Win/lose count 6.5/4.0 (2.5)\n",
            "Epoch 011/020 | Loss 1.8072 | Win/lose count 7.5/1.0 (6.5)\n",
            "Epoch 012/020 | Loss 1.7739 | Win/lose count 10.5/3.0 (7.5)\n",
            "Epoch 013/020 | Loss 1.7408 | Win/lose count 7.5/0 (7.5)\n",
            "Epoch 014/020 | Loss 1.7922 | Win/lose count 5.0/4.0 (1.0)\n",
            "Epoch 015/020 | Loss 1.7361 | Win/lose count 5.0/1.0 (4.0)\n",
            "Epoch 016/020 | Loss 1.7776 | Win/lose count 14.5/4.0 (10.5)\n",
            "Epoch 017/020 | Loss 1.7529 | Win/lose count 9.0/2.0 (7.0)\n",
            "Epoch 018/020 | Loss 1.7337 | Win/lose count 16.0/2.0 (14.0)\n",
            "Epoch 019/020 | Loss 1.7281 | Win/lose count 14.0/0 (14.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfTQ9gCljZAm",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 9__ Test both algorithms and compare their performances. Which issue(s) do you observe? Observe also different behaviors by changing the temperature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tZV2LDtjZAn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "outputId": "69f589fd-1b79-412c-983a-cea71581f363"
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T,temperature=0.9)\n",
        "agent_cnn = DQN_CNN(size, lr=.001, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "agent_cnn.load(name_weights='cnn_trainmodel.h5',name_model='cnn_trainmodel.json')\n",
        "\n",
        "agent_fc = DQN_FC(size, lr=.001, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "agent_cnn.load(name_weights='fc_trainmodel.h5',name_model='fc_trainmodel.json')\n",
        "print('Test of the CNN')\n",
        "test(agent_cnn,env,epochs_test,prefix='cnn_test')\n",
        "print('Test of the FC')\n",
        "test(agent_fc,env,epochs_test,prefix='fc_test')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test of the CNN\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-a2f65bbefc12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0magent_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fc_trainmodel.h5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fc_trainmodel.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test of the CNN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent_cnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cnn_test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test of the FC'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent_fc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fc_test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-67cd221e9099>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(agent, env, epochs, prefix)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# At each epoch, we restart to a fresh game and get the initial state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# This assumes that the games will end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-d652a23a5dcf>\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mbonus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_size\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mbonus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbonus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.binomial\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcommon.pyx\u001b[0m in \u001b[0;36mnumpy.random.common.check_constraint\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: p < 0, p > 1 or p is NaN"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXljOD0UjZAp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "20ef3426-f3ed-42bc-d834-a202171973a4"
      },
      "source": [
        "HTML(display_videos('cnn_test10.mp4'))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfvfxatDjZAr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "24dff447-74cc-4c1d-9959-2941df30ff2f"
      },
      "source": [
        "HTML(display_videos('fc_test10.mp4'))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAEz1tZGF0AAACrQYF//+p3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1MiByMjg1NCBlOWE1OTAzIC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAxNyAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MToweDExMSBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MCBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD00IHRocmVhZHM9MyBsb29rYWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFjZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJhbWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdlaWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MjUgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVzaD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBxcG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAAFjZYiEADv//vb8/AptUwn/LZ/+iL/lb+9P2a61uFE7M7QacwPQC/3cd/Xi1bCrc27LcdG8bJkAU3Roif7wCeTfHLadReAHZcF4KG8X1vl/gU1dKC/wKSgoS5K7m0lvJIz5QpI5PTDqzuy+4vO8GMQ7YI9yavubQ+XBWliBEE9w6aWWvxJZaQqd4yeW6dtC+ITFGwYhMK44guXKHSdVOOoKGYNMaOMv17k1+OLQzcLAxiddMcL3XciSKetPmAS4iCiKwdJ8DV4pccZpukidEbETpFuLleI1rjdpEdK6OytQAN3o4iYxtPfQKfOnPbTfSwCDhKAEI4TxEqYDmPaRvzoDhzyYPFimASisYLH82UZ7XyjsR4gRnIZR++bUPQrsyz1eEdEF0jumE3z3vO8qlxSUeHnAdbgEXC+ghHinT5UNAKQYD6VV/n23pGAsImFaRzaJoYpMm8OLdtnWtFQ2HDGTsAAooQAAAA1BmiRsQ7/+qZYAAJWAAAAACkGeQniF/wAAsoEAAAAPAZ5hdEK/AAcVsDQ855ilAAAADwGeY2pCvwAHE5w0SueYpQAAABNBmmhJqEFomUwId//+qZYAAJWBAAAADEGehkURLC//AACygQAAAA8BnqV0Qr8ABxWwNDznmKUAAAAPAZ6nakK/AAcTnDRK55ilAAAAE0GarEmoQWyZTAh3//6plgAAlYAAAAAMQZ7KRRUsL/8AALKBAAAADwGe6XRCvwAHFbA0POeYpQAAAA8BnutqQr8ABxOcNErnmKUAAAATQZrwSahBbJlMCHf//qmWAACVgQAAAAxBnw5FFSwv/wAAsoEAAAAPAZ8tdEK/AAcVsDQ855ilAAAADwGfL2pCvwAHE5w0SueYpQAAABNBmzRJqEFsmUwId//+qZYAAJWAAAAADEGfUkUVLC//AACygQAAAA8Bn3F0Qr8ABxWwNDznmKUAAAAPAZ9zakK/AAcTnDRK55ilAAAAE0GbeEmoQWyZTAh3//6plgAAlYEAAAAMQZ+WRRUsL/8AALKAAAAADwGftXRCvwAHFbA0POeYpQAAAA8Bn7dqQr8ABxOcNErnmKUAAAATQZu8SahBbJlMCHf//qmWAACVgAAAAAxBn9pFFSwv/wAAsoEAAAAPAZ/5dEK/AAcVsDQ855ilAAAADwGf+2pCvwAHE5w0SueYpQAAABNBm+BJqEFsmUwId//+qZYAAJWBAAAADEGeHkUVLC//AACygAAAAA8Bnj10Qr8ABxWwNDznmKUAAAAPAZ4/akK/AAcTnDRK55ilAAAAE0GaJEmoQWyZTAh3//6plgAAlYAAAAAMQZ5CRRUsL/8AALKBAAAADwGeYXRCvwAHFbA0POeYpQAAAA8BnmNqQr8ABxOcNErnmKUAAAATQZpoSahBbJlMCHf//qmWAACVgQAAAAxBnoZFFSwv/wAAsoEAAAAPAZ6ldEK/AAcVsDQ855ilAAAADwGep2pCvwAHE5w0SueYpQAAABNBmqxJqEFsmUwId//+qZYAAJWAAAAADEGeykUVLC//AACygQAAAA8Bnul0Qr8ABxWwNDznmKUAAAAPAZ7rakK/AAcTnDRK55ilAAAAE0Ga8EmoQWyZTAh3//6plgAAlYEAAAAMQZ8ORRUsL/8AALKBAAAADwGfLXRCvwAHFbA0POeYpQAAAA8Bny9qQr8ABxOcNErnmKUAAAATQZs0SahBbJlMCHf//qmWAACVgAAAAAxBn1JFFSwv/wAAsoEAAAAPAZ9xdEK/AAcVsDQ855ilAAAADwGfc2pCvwAHE5w0SueYpQAAABNBm3hJqEFsmUwId//+qZYAAJWBAAAADEGflkUVLC//AACygAAAAA8Bn7V0Qr8ABxWwNDznmKUAAAAPAZ+3akK/AAcTnDRK55ilAAAAE0GbvEmoQWyZTAh3//6plgAAlYAAAAAMQZ/aRRUsL/8AALKBAAAADwGf+XRCvwAHFbA0POeYpQAAAA8Bn/tqQr8ABxOcNErnmKUAAAATQZvgSahBbJlMCHf//qmWAACVgQAAAAxBnh5FFSwv/wAAsoAAAAAPAZ49dEK/AAcVsDQ855ilAAAADwGeP2pCvwAHE5w0SueYpQAAABNBmiRJqEFsmUwId//+qZYAAJWAAAAADEGeQkUVLC//AACygQAAAA8BnmF0Qr8ABxWwNDznmKUAAAAPAZ5jakK/AAcTnDRK55ilAAAAE0GaaEmoQWyZTAh3//6plgAAlYEAAAAMQZ6GRRUsL/8AALKBAAAADwGepXRCvwAHFbA0POeYpQAAAA8BnqdqQr8ABxOcNErnmKUAAAATQZqsSahBbJlMCHf//qmWAACVgAAAAAxBnspFFSwv/wAAsoEAAAAPAZ7pdEK/AAcVsDQ855ilAAAADwGe62pCvwAHE5w0SueYpQAAABNBmvBJqEFsmUwId//+qZYAAJWBAAAADEGfDkUVLC//AACygQAAAA8Bny10Qr8ABxWwNDznmKUAAAAPAZ8vakK/AAcTnDRK55ilAAAAE0GbNEmoQWyZTAh3//6plgAAlYAAAAAMQZ9SRRUsL/8AALKBAAAADwGfcXRCvwAHFbA0POeYpQAAAA8Bn3NqQr8ABxOcNErnmKUAAAATQZt4SahBbJlMCHf//qmWAACVgQAAAAxBn5ZFFSwv/wAAsoAAAAAPAZ+1dEK/AAcVsDQ855ilAAAADwGft2pCvwAHE5w0SueYpQAAABNBm7xJqEFsmUwId//+qZYAAJWAAAAADEGf2kUVLC//AACygQAAAA8Bn/l0Qr8ABxWwNDznmKUAAAAPAZ/7akK/AAcTnDRK55ilAAAAE0Gb4EmoQWyZTAh3//6plgAAlYEAAAAMQZ4eRRUsL/8AALKAAAAADwGePXRCvwAHFbA0POeYpQAAAA8Bnj9qQr8ABxOcNErnmKUAAAATQZokSahBbJlMCHf//qmWAACVgAAAAAxBnkJFFSwv/wAAsoEAAAAPAZ5hdEK/AAcVsDQ855ilAAAADwGeY2pCvwAHE5w0SueYpQAAABNBmmhJqEFsmUwId//+qZYAAJWBAAAADEGehkUVLC//AACygQAAAA8BnqV0Qr8ABxWwNDznmKUAAAAPAZ6nakK/AAcTnDRK55ilAAAAE0GarEmoQWyZTAh3//6plgAAlYAAAAAMQZ7KRRUsL/8AALKBAAAADwGe6XRCvwAHFbA0POeYpQAAAA8BnutqQr8ABxOcNErnmKUAAAATQZrwSahBbJlMCHf//qmWAACVgQAAAAxBnw5FFSwv/wAAsoEAAAAPAZ8tdEK/AAcVsDQ855ilAAAADwGfL2pCvwAHE5w0SueYpQAAABNBmzRJqEFsmUwId//+qZYAAJWAAAAADEGfUkUVLC//AACygQAAAA8Bn3F0Qr8ABxWwNDznmKUAAAAPAZ9zakK/AAcTnDRK55ilAAAAE0GbeEmoQWyZTAh3//6plgAAlYEAAAAMQZ+WRRUsL/8AALKAAAAADwGftXRCvwAHFbA0POeYpQAAAA8Bn7dqQr8ABxOcNErnmKUAAAATQZu8SahBbJlMCHf//qmWAACVgAAAAAxBn9pFFSwv/wAAsoEAAAAPAZ/5dEK/AAcVsDQ855ilAAAADwGf+2pCvwAHE5w0SueYpQAAABNBm+BJqEFsmUwId//+qZYAAJWBAAAADEGeHkUVLC//AACygAAAAA8Bnj10Qr8ABxWwNDznmKUAAAAPAZ4/akK/AAcTnDRK55ilAAAAE0GaJEmoQWyZTAh3//6plgAAlYAAAAAMQZ5CRRUsL/8AALKBAAAADwGeYXRCvwAHFbA0POeYpQAAAA8BnmNqQr8ABxOcNErnmKUAAAATQZpoSahBbJlMCHf//qmWAACVgQAAAAxBnoZFFSwv/wAAsoEAAAAPAZ6ldEK/AAcVsDQ855ilAAAADwGep2pCvwAHE5w0SueYpQAAABNBmqxJqEFsmUwId//+qZYAAJWAAAAADEGeykUVLC//AACygQAAAA8Bnul0Qr8ABxWwNDznmKUAAAAPAZ7rakK/AAcTnDRK55ilAAAAE0Ga8EmoQWyZTAh3//6plgAAlYEAAAAMQZ8ORRUsL/8AALKBAAAADwGfLXRCvwAHFbA0POeYpQAAAA8Bny9qQr8ABxOcNErnmKUAAAATQZs0SahBbJlMCHf//qmWAACVgAAAAAxBn1JFFSwv/wAAsoEAAAAPAZ9xdEK/AAcVsDQ855ilAAAADwGfc2pCvwAHE5w0SueYpQAAABNBm3hJqEFsmUwId//+qZYAAJWBAAAADEGflkUVLC//AACygAAAAA8Bn7V0Qr8ABxWwNDznmKUAAAAPAZ+3akK/AAcTnDRK55ilAAAAE0GbvEmoQWyZTAh3//6plgAAlYAAAAAMQZ/aRRUsL/8AALKBAAAADwGf+XRCvwAHFbA0POeYpQAAAA8Bn/tqQr8ABxOcNErnmKUAAAATQZvgSahBbJlMCHf//qmWAACVgQAAAAxBnh5FFSwv/wAAsoAAAAAPAZ49dEK/AAcVsDQ855ilAAAADwGeP2pCvwAHE5w0SueYpQAAABNBmiRJqEFsmUwId//+qZYAAJWAAAAADEGeQkUVLC//AACygQAAAA8BnmF0Qr8ABxWwNDznmKUAAAAPAZ5jakK/AAcTnDRK55ilAAAAE0GaaEmoQWyZTAh3//6plgAAlYEAAAAMQZ6GRRUsL/8AALKBAAAADwGepXRCvwAHFbA0POeYpQAAAA8BnqdqQr8ABxOcNErnmKUAAAATQZqsSahBbJlMCHf//qmWAACVgAAAAAxBnspFFSwv/wAAsoEAAAAPAZ7pdEK/AAcVsDQ855ilAAAADwGe62pCvwAHE5w0SueYpQAAABNBmvBJqEFsmUwId//+qZYAAJWBAAAADEGfDkUVLC//AACygQAAAA8Bny10Qr8ABxWwNDznmKUAAAAPAZ8vakK/AAcTnDRK55ilAAAAE0GbNEmoQWyZTAh3//6plgAAlYAAAAAMQZ9SRRUsL/8AALKBAAAADwGfcXRCvwAHFbA0POeYpQAAAA8Bn3NqQr8ABxOcNErnmKUAAAATQZt4SahBbJlMCHf//qmWAACVgQAAAAxBn5ZFFSwv/wAAsoAAAAAPAZ+1dEK/AAcVsDQ855ilAAAADwGft2pCvwAHE5w0SueYpQAAABNBm7xJqEFsmUwId//+qZYAAJWAAAAADEGf2kUVLC//AACygQAAAA8Bn/l0Qr8ABxWwNDznmKUAAAAPAZ/7akK/AAcTnDRK55ilAAAAEkGb4EmoQWyZTAhv//6nhAABJwAAAAxBnh5FFSwv/wAAsoAAAAAPAZ49dEK/AAcVsDQ855ilAAAADwGeP2pCvwAHE5w0SueYpQAAABJBmiRJqEFsmUwIb//+p4QAAScAAAAMQZ5CRRUsL/8AALKBAAAADwGeYXRCvwAHFbA0POeYpQAAAA8BnmNqQr8ABxOcNErnmKUAAAASQZpoSahBbJlMCF///oywAASNAAAADEGehkUVLC//AACygQAAAA8BnqV0Qr8ABxWwNDznmKUAAAAPAZ6nakK/AAcTnDRK55ilAAAAGkGaqUuoQhBbJEYIKAfyAf2HgCFf/jhAABFwAAAMiG1vb3YAAABsbXZoZAAAAAAAAAAAAAAAAAAAA+gAAB+QAAEAAAEAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIAAAuydHJhawAAAFx0a2hkAAAAAwAAAAAAAAAAAAAAAQAAAAAAAB+QAAAAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAEQAAABEAAAAAAAJGVkdHMAAAAcZWxzdAAAAAAAAAABAAAfkAAABAAAAQAAAAALKm1kaWEAAAAgbWRoZAAAAAAAAAAAAAAAAAAAMgAAAZQAVcQAAAAAAC1oZGxyAAAAAAAAAAB2aWRlAAAAAAAAAAAAAAAAVmlkZW9IYW5kbGVyAAAACtVtaW5mAAAAFHZtaGQAAAABAAAAAAAAAAAAAAAkZGluZgAAABxkcmVmAAAAAAAAAAEAAAAMdXJsIAAAAAEAAAqVc3RibAAAAJVzdHNkAAAAAAAAAAEAAACFYXZjMQAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAEQARAASAAAAEgAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABj//wAAAC9hdmNDAfQADf/hABdn9AANkZsoIhHQgAAAAwCAAAAZB4oUywEABWjr48RIAAAAGHN0dHMAAAAAAAAAAQAAAMoAAAIAAAAAFHN0c3MAAAAAAAAAAQAAAAEAAAZgY3R0cwAAAAAAAADKAAAAAQAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABAAAAAAcc3RzYwAAAAAAAAABAAAAAQAAAMoAAAABAAADPHN0c3oAAAAAAAAAAAAAAMoAAAQYAAAAEQAAAA4AAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAWAAAAEAAAABMAAAATAAAAFgAAABAAAAATAAAAEwAAABYAAAAQAAAAEwAAABMAAAAeAAAAFHN0Y28AAAAAAAAAAQAAADAAAABidWR0YQAAAFptZXRhAAAAAAAAACFoZGxyAAAAAAAAAABtZGlyYXBwbAAAAAAAAAAAAAAAAC1pbHN0AAAAJal0b28AAAAdZGF0YQAAAAEAAAAATGF2ZjU3LjgzLjEwMA==\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_oZcT9zjZAu",
        "colab_type": "text"
      },
      "source": [
        "temp = 0.1 : CNN = 0.65 , FC = -0.1\n",
        "\n",
        "temp = 0.2 : CNN = 1.25 , FC = -0.05\n",
        "\n",
        "temp = 0.3 : CNN = 1,3 , FC = 0.025\n",
        "\n",
        "temp = 0.4 : CNN = 1,75 , FC = 0.5\n",
        "\n",
        "temp = 0.5 : CNN = 2,8 , FC = 0.65\n",
        "\n",
        "temp = 0.6 : CNN = 3,675 , FC = 0,75\n",
        "\n",
        "temp = 0.7 : CNN = 4,17 , FC = 0.85\n",
        "\n",
        "temp = 0.8 : CNN = 5,87 , FC = 0,65\n",
        "\n",
        "temp = 0.9 : CNN = 6,97 , FC = 1,85\n",
        "\n",
        "\n",
        "We can say that the CNN is more efficient than the FC in general and the gap of performance increase when the temperature increase.\n",
        "\n",
        "After a moment the mouse does not explore the grid anymore and is in a loop. This happen more frequently when the temperature is low.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZebizySjZAu",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "\n",
        "The algorithm tends to not explore the map which can be an issue. We propose two ideas in order to encourage exploration:\n",
        "1. Incorporating a decreasing $\\epsilon$-greedy exploration. You can use the method ```set_epsilon```\n",
        "2. Append via the environment a new state that describes if a cell has been visited or not\n",
        "\n",
        "***\n",
        "__Question 10__ Design a new ```train_explore``` function and environment class ```EnvironmentExploring``` to tackle the issue of exploration.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9nNRJhtjZAv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_explore(agent,env,epoch,prefix=''):\n",
        "    pass\n",
        "        \n",
        "class EnvironmentExploring(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        pass\n",
        "    \n",
        "## use those samples of code:\n",
        "#In train explore:\n",
        "state, reward, game_over = env.act(action, train=True)\n",
        "\n",
        "## In Environment exploring:\n",
        "# You will have to change n_state to 3 because you will use one more layer!\n",
        "reward = 0\n",
        "if train:\n",
        "    reward = -self.malus_position[self.x, self.y]\n",
        "self.malus_position[self.x, self.y] = 0.1\n",
        "\n",
        "reward = reward + self.board[self.x, self.y]\n",
        "# 3 \"feature\" states instead of 2\n",
        "state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laEn8FxY1ClL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_explore(agent,env,epoch,decay_parameter_epsilon=0.3,prefix=''):\n",
        "    #New training procedure that tries to improve the exploration of the algorithm\n",
        "    #decay_parameter_epsilon in order to use the decreasing $\\epsilon$-greedy exploration\n",
        "    \n",
        "    \n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "    decay_parameter_epsilon = 0.5\n",
        "    print(\"epsilon\",agent.epsilon)\n",
        "    for e in range(epoch):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "        if e % 5 == 0 and e!= 0:\n",
        "            agent.set_epsilon(agent.epsilon*(decay_parameter_epsilon))\n",
        "            print(\"epsilon\",agent.epsilon)\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action, train=True)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')\n",
        "        \n",
        "class EnvironmentExploring(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        grid_size = grid_size+4\n",
        "        self.grid_size = grid_size\n",
        "        self.max_time = max_time\n",
        "        self.temperature = temperature\n",
        "\n",
        "        #board on which one plays\n",
        "        self.board = np.zeros((grid_size,grid_size))\n",
        "        self.position = np.zeros((grid_size,grid_size))\n",
        "        self.malus_position = np.zeros((grid_size,grid_size)) #define maluses when going to a previously visited position\n",
        "        # coordinate of the cat\n",
        "        self.x = 0\n",
        "        self.y = 1\n",
        "\n",
        "        # self time\n",
        "        self.t = 0\n",
        "\n",
        "        self.scale=16\n",
        "\n",
        "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "    def draw(self,e):\n",
        "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
        "\n",
        "    def get_frame(self,t):\n",
        "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
        "        b[self.board>0,0] = 256\n",
        "        b[self.board < 0, 2] = 256\n",
        "        b[self.x,self.y,:]=256\n",
        "        b[-2:,:,:]=0\n",
        "        b[:,-2:,:]=0\n",
        "        b[:2,:,:]=0\n",
        "        b[:,:2,:]=0\n",
        "        \n",
        "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        self.to_draw[t,:,:,:]=b\n",
        "\n",
        "\n",
        "    def act(self, action,train=False):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "        #During the training phase going back to a position where the rat have already been before tends to decrease the \n",
        "        #total reward hence there is this train parameter that we have added (it tries to enforce the exploration)\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.malus_position = np.zeros((self.grid_size,self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[:, -2:] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0:\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "\n",
        "        self.t = self.t + 1     \n",
        "        \n",
        "        ## In Environment exploring:\n",
        "        # You will have to change n_state to 3 because you will use one more layer!\n",
        "        reward = 0\n",
        "        if train:\n",
        "            reward = -self.malus_position[self.x, self.y]\n",
        "        self.malus_position[self.x, self.y] = 1\n",
        "\n",
        "        reward = reward + self.board[self.x, self.y]\n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "        \n",
        "        # 3 \"feature\" states instead of 2\n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                        self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "\n",
        "        return state, reward, game_over\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[:,-2:] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "        self.t = 0\n",
        "\n",
        "        self.malus_position = np.zeros((self.grid_size, self.grid_size))\n",
        "        #At the begining the malus_position array must be setted to zero\n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                        self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQLdunn8jZAx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "outputId": "20720a97-7b3b-4fbb-f2de-677d0d181dc4"
      },
      "source": [
        "# Training\n",
        "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.5)\n",
        "agent = DQN_CNN(size, lr=.1, epsilon = 0.9, memory_size=2000, batch_size = 32,n_state=3)\n",
        "train_explore(agent, env, 30, prefix='cnn_train_explore')\n",
        "HTML(display_videos('cnn_train_explore10.mp4'))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epsilon 0.9\n",
            "Epoch 000/030 | Loss 2.0018 | Win/lose count 18.0/14.0 (4.0)\n",
            "Epoch 001/030 | Loss 2.0399 | Win/lose count 18.0/18.0 (0.0)\n",
            "Epoch 002/030 | Loss 1.7784 | Win/lose count 10.0/10.0 (0.0)\n",
            "Epoch 003/030 | Loss 1.8755 | Win/lose count 19.0/28.0 (-9.0)\n",
            "Epoch 004/030 | Loss 1.7655 | Win/lose count 10.5/16.0 (-5.5)\n",
            "epsilon 0.45\n",
            "Epoch 005/030 | Loss 1.8000 | Win/lose count 17.0/17.0 (0.0)\n",
            "Epoch 006/030 | Loss 1.6487 | Win/lose count 23.5/19.0 (4.5)\n",
            "Epoch 007/030 | Loss 1.9579 | Win/lose count 23.0/17.0 (6.0)\n",
            "Epoch 008/030 | Loss 1.6981 | Win/lose count 24.0/27.0 (-3.0)\n",
            "Epoch 009/030 | Loss 1.6249 | Win/lose count 20.0/29.0 (-9.0)\n",
            "epsilon 0.225\n",
            "Epoch 010/030 | Loss 1.9075 | Win/lose count 26.0/19.0 (7.0)\n",
            "Epoch 011/030 | Loss 1.7826 | Win/lose count 24.5/22.0 (2.5)\n",
            "Epoch 012/030 | Loss 1.6431 | Win/lose count 22.0/15.0 (7.0)\n",
            "Epoch 013/030 | Loss 1.6740 | Win/lose count 23.0/28.0 (-5.0)\n",
            "Epoch 014/030 | Loss 1.6808 | Win/lose count 26.0/26.0 (0.0)\n",
            "epsilon 0.1125\n",
            "Epoch 015/030 | Loss 1.5511 | Win/lose count 19.0/25.0 (-6.0)\n",
            "Epoch 016/030 | Loss 1.7333 | Win/lose count 25.5/12.0 (13.5)\n",
            "Epoch 017/030 | Loss 1.6642 | Win/lose count 15.0/16.0 (-1.0)\n",
            "Epoch 018/030 | Loss 1.9938 | Win/lose count 15.5/24.0 (-8.5)\n",
            "Epoch 019/030 | Loss 1.8770 | Win/lose count 21.0/23.0 (-2.0)\n",
            "epsilon 0.05625\n",
            "Epoch 020/030 | Loss 1.6609 | Win/lose count 24.5/23.0 (1.5)\n",
            "Epoch 021/030 | Loss 1.6125 | Win/lose count 14.0/23.0 (-9.0)\n",
            "Epoch 022/030 | Loss 1.7547 | Win/lose count 12.0/25.0 (-13.0)\n",
            "Epoch 023/030 | Loss 1.7937 | Win/lose count 18.5/17.0 (1.5)\n",
            "Epoch 024/030 | Loss 1.7001 | Win/lose count 21.0/26.0 (-5.0)\n",
            "epsilon 0.028125\n",
            "Epoch 025/030 | Loss 1.6483 | Win/lose count 12.5/17.0 (-4.5)\n",
            "Epoch 026/030 | Loss 1.6162 | Win/lose count 23.5/11.0 (12.5)\n",
            "Epoch 027/030 | Loss 1.3008 | Win/lose count 11.5/13.0 (-1.5)\n",
            "Epoch 028/030 | Loss 1.5765 | Win/lose count 21.0/9.0 (12.0)\n",
            "Epoch 029/030 | Loss 1.5337 | Win/lose count 12.0/20.0 (-8.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rimb8rp5jZAz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "outputId": "e684861d-af76-4ff7-cf94-2a40223543fc"
      },
      "source": [
        "# Evaluation\n",
        "test(agent,env,epochs_test,prefix='cnn_test_explore')\n",
        "HTML(display_videos('cnn_test_explore10.mp4'))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 0/0. Average score (0.0)\n",
            "Win/lose count 3.0/0. Average score (1.5)\n",
            "Win/lose count 2.5/2.0. Average score (1.1666666666666667)\n",
            "Win/lose count 1.0/0. Average score (1.125)\n",
            "Win/lose count 0/1.0. Average score (0.7)\n",
            "Win/lose count 1.0/1.0. Average score (0.5833333333333334)\n",
            "Win/lose count 1.5/3.0. Average score (0.2857142857142857)\n",
            "Win/lose count 1.0/0. Average score (0.375)\n",
            "Win/lose count 1.0/2.0. Average score (0.2222222222222222)\n",
            "Win/lose count 1.5/1.0. Average score (0.25)\n",
            "Win/lose count 2.5/0. Average score (0.45454545454545453)\n",
            "Win/lose count 3.0/1.0. Average score (0.5833333333333334)\n",
            "Win/lose count 0.5/1.0. Average score (0.5)\n",
            "Win/lose count 1.5/2.0. Average score (0.42857142857142855)\n",
            "Win/lose count 1.5/2.0. Average score (0.36666666666666664)\n",
            "Win/lose count 1.0/2.0. Average score (0.28125)\n",
            "Win/lose count 1.0/0. Average score (0.3235294117647059)\n",
            "Win/lose count 3.5/1.0. Average score (0.4444444444444444)\n",
            "Win/lose count 1.0/0. Average score (0.47368421052631576)\n",
            "Win/lose count 0.5/1.0. Average score (0.425)\n",
            "Final score: 0.425\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAFZ9tZGF0AAACrQYF//+p3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1MiByMjg1NCBlOWE1OTAzIC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAxNyAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MToweDExMSBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MCBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD00IHRocmVhZHM9MyBsb29rYWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFjZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJhbWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdlaWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MjUgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVzaD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBxcG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAAMyZYiEADP//vaG+BTYUyP+T7/8I/+5H7cfWfrixkIJvrVeQ9GAMl8a/5lGYaXpyc8t7R+vTNAEZz6HlLJIofgUkwDfMsjnE+J8s6FP3lFrFWUnapilQooJthtp0b3Iay1tUsUppMZzl9AQmZ/mBmEbVGlq9B2geig31oy3jvCT/BVHj9gxxTvxo9/uOpIFWFCW/i8tYb4+K8ZhpDZeaUvPogbJOzzuNZcn87ty1pG1aV2qsF8ajMDJqkR6gAAn8AFrHiq7NCCBpaC72hP5jBNYfMLmSYIatXifVX6a5GNqEjvSwJMwIXO5LleJxtV6wERaiH3Gk1Ygb5D+91VEI7iTtWHylxgKxXUhceMCD/6RCGFVzm3x5YDUTnjmu2qakqsQlIZGaQtrMlM2BAV/2hKJuZkaATyJD5ExJ6KBf49fEd2FwCdikVP1OF5jNuZR2R0kyGhlLsg+wSumtR8ODdHikR559+YexQfHqoJGUEYTo7J8CeT3rEveP02NTWP/+reMSzQess9lgqJG/jjSRX9ECMjW+1GJp6R7j0FBmiEJCQzwPthzJI8ZRXFT7hO0gDilSMMcpW6SQ9QFlJA9oCMdkglpVmUDn9JRxGp03KfiBOL8GZMR8ST82fjYYtzkS5fkZO0SaN1vkwNYlcvIltcBFvVAFyVlbU6hn44JHTDZoR42ql7QFLXg954XphKd2Q5k3bcyM6omEDk6igLU6Vti7Tu6/SxL0HZIvZ5+cvG5JQHxXfDC4RifQdwlTtrSh/z6SNmRMdNM6lZDN028N8gUPMBxCDGAnEiWMVjEqg6KV3Gik6EhKcbPMO2c1aFENNfzSlJZgamTK6SHkeGsiot4Ud2uKqYbln5FLi8Jq7ifhCHDIUcUuer1SvuGvdxuP7gsJL0JbRTBKcasnh7ft+hVMpsjLYtceABjxKgIJBdtaSD6my5a1iaMgfEkD9VliGplS4K9OnEZPDzLvzRVEIa4HAOZ6dn5rNAkj30e/CTjZvlgWwGmW9kAJh+BiudcLFgwetC8McmXtm+QKwC7ifYZS48HUO4eC2d5YtJOBR5DfNUPesLoxgQa2fWnbfZh4AAAtoEAAAAVQZohbEM//p4QAbngjn6IBBBA4zZQAAAAGEGaQjwhkymEN//+p4QAsHon+pHRpDTbQQAAABlBmmNJ4Q8mUwIb//6nhAEMQBZtiANIaXTAAAAAG0GahEnhDyZTAh3//qmWAO40hJtrpdA4f3kfMQAAABZBmqhJ4Q8mUwId//6plgM3wo+mKJuBAAAADkGexkURPC//AZU/+zUhAAAAEAGe5XRCvwIfZV3dwN2/KaEAAAAQAZ7nakK/Ah6VsYKJPsNIwAAAABNBmuxJqEFomUwId//+qZYAAJWAAAAADEGfCkURLC//AACygQAAABABnyl0Qr8CH2Vd3cDdvymgAAAAEAGfK2pCvwIelbGCiT7DSMAAAAATQZswSahBbJlMCHf//qmWAACVgQAAAAxBn05FFSwv/wAAsoEAAAAQAZ9tdEK/Ah9lXd3A3b8poQAAABABn29qQr8CHpWxgok+w0jAAAAAE0GbdEmoQWyZTAh3//6plgAAlYAAAAAMQZ+SRRUsL/8AALKBAAAAEAGfsXRCvwIfZV3dwN2/KaAAAAAQAZ+zakK/Ah6VsYKJPsNIwAAAABNBm7hJqEFsmUwId//+qZYAAJWBAAAADEGf1kUVLC//AACygAAAABABn/V0Qr8CH2Vd3cDdvymhAAAAEAGf92pCvwIelbGCiT7DSMEAAAATQZv8SahBbJlMCHf//qmWAACVgAAAAAxBnhpFFSwv/wAAsoEAAAAQAZ45dEK/Ah9lXd3A3b8poAAAABABnjtqQr8CHpWxgok+w0jBAAAAE0GaIEmoQWyZTAh3//6plgAAlYEAAAAMQZ5eRRUsL/8AALKAAAAAEAGefXRCvwIfZV3dwN2/KaAAAAAQAZ5/akK/Ah6VsYKJPsNIwQAAABNBmmRJqEFsmUwId//+qZYAAJWAAAAADEGegkUVLC//AACygQAAABABnqF0Qr8CH2Vd3cDdvymgAAAAEAGeo2pCvwIelbGCiT7DSMEAAAATQZqoSahBbJlMCHf//qmWAACVgQAAAAxBnsZFFSwv/wAAsoEAAAAQAZ7ldEK/Ah9lXd3A3b8poQAAABABnudqQr8CHpWxgok+w0jAAAAAE0Ga7EmoQWyZTAh3//6plgAAlYAAAAAMQZ8KRRUsL/8AALKBAAAAEAGfKXRCvwIfZV3dwN2/KaAAAAAQAZ8rakK/Ah6VsYKJPsNIwAAAABNBmzBJqEFsmUwId//+qZYAAJWBAAAADEGfTkUVLC//AACygQAAABABn210Qr8CH2Vd3cDdvymhAAAAEAGfb2pCvwIelbGCiT7DSMAAAAATQZt0SahBbJlMCHf//qmWAACVgAAAAAxBn5JFFSwv/wAAsoEAAAAQAZ+xdEK/Ah9lXd3A3b8poAAAABABn7NqQr8CHpWxgok+w0jAAAAAE0GbuEmoQWyZTAh3//6plgAAlYEAAAAMQZ/WRRUsL/8AALKAAAAAEAGf9XRCvwIfZV3dwN2/KaEAAAAQAZ/3akK/Ah6VsYKJPsNIwQAAABNBm/xJqEFsmUwId//+qZYAAJWAAAAADEGeGkUVLC//AACygQAAABABnjl0Qr8CH2Vd3cDdvymgAAAAEAGeO2pCvwIelbGCiT7DSMEAAAATQZogSahBbJlMCHf//qmWAACVgQAAAAxBnl5FFSwv/wAAsoAAAAAQAZ59dEK/Ah9lXd3A3b8poAAAABABnn9qQr8CHpWxgok+w0jBAAAAE0GaZEmoQWyZTAh3//6plgAAlYAAAAAMQZ6CRRUsL/8AALKBAAAAEAGeoXRCvwIfZV3dwN2/KaAAAAAQAZ6jakK/Ah6VsYKJPsNIwQAAABNBmqhJqEFsmUwId//+qZYAAJWBAAAADEGexkUVLC//AACygQAAABABnuV0Qr8CH2Vd3cDdvymhAAAAEAGe52pCvwIelbGCiT7DSMAAAAATQZrsSahBbJlMCHf//qmWAACVgAAAAAxBnwpFFSwv/wAAsoEAAAAQAZ8pdEK/Ah9lXd3A3b8poAAAABABnytqQr8CHpWxgok+w0jAAAAAE0GbMEmoQWyZTAh3//6plgAAlYEAAAAMQZ9ORRUsL/8AALKBAAAAEAGfbXRCvwIfZV3dwN2/KaEAAAAQAZ9vakK/Ah6VsYKJPsNIwAAAABNBm3RJqEFsmUwId//+qZYAAJWAAAAADEGfkkUVLC//AACygQAAABABn7F0Qr8CH2Vd3cDdvymgAAAAEAGfs2pCvwIelbGCiT7DSMAAAAATQZu4SahBbJlMCHf//qmWAACVgQAAAAxBn9ZFFSwv/wAAsoAAAAAQAZ/1dEK/Ah9lXd3A3b8poQAAABABn/dqQr8CHpWxgok+w0jBAAAAE0Gb/EmoQWyZTAh3//6plgAAlYAAAAAMQZ4aRRUsL/8AALKBAAAAEAGeOXRCvwIfZV3dwN2/KaAAAAAQAZ47akK/Ah6VsYKJPsNIwQAAABNBmiBJqEFsmUwId//+qZYAAJWBAAAADEGeXkUVLC//AACygAAAABABnn10Qr8CH2Vd3cDdvymgAAAAEAGef2pCvwIelbGCiT7DSMEAAAATQZpkSahBbJlMCHf//qmWAACVgAAAAAxBnoJFFSwv/wAAsoEAAAAQAZ6hdEK/Ah9lXd3A3b8poAAAABABnqNqQr8CHpWxgok+w0jBAAAAE0GaqEmoQWyZTAh3//6plgAAlYEAAAAMQZ7GRRUsL/8AALKBAAAAEAGe5XRCvwIfZV3dwN2/KaEAAAAQAZ7nakK/Ah6VsYKJPsNIwAAAABNBmuxJqEFsmUwId//+qZYAAJWAAAAADEGfCkUVLC//AACygQAAABABnyl0Qr8CH2Vd3cDdvymgAAAAEAGfK2pCvwIelbGCiT7DSMAAAAATQZswSahBbJlMCHf//qmWAACVgQAAAAxBn05FFSwv/wAAsoEAAAAQAZ9tdEK/Ah9lXd3A3b8poQAAABABn29qQr8CHpWxgok+w0jAAAAAE0GbdEmoQWyZTAh3//6plgAAlYAAAAAMQZ+SRRUsL/8AALKBAAAAEAGfsXRCvwIfZV3dwN2/KaAAAAAQAZ+zakK/Ah6VsYKJPsNIwAAAABNBm7hJqEFsmUwId//+qZYAAJWBAAAADEGf1kUVLC//AACygAAAABABn/V0Qr8CH2Vd3cDdvymhAAAAEAGf92pCvwIelbGCiT7DSMEAAAATQZv8SahBbJlMCHf//qmWAACVgAAAAAxBnhpFFSwv/wAAsoEAAAAQAZ45dEK/Ah9lXd3A3b8poAAAABABnjtqQr8CHpWxgok+w0jBAAAAE0GaIEmoQWyZTAh3//6plgAAlYEAAAAMQZ5eRRUsL/8AALKAAAAAEAGefXRCvwIfZV3dwN2/KaAAAAAQAZ5/akK/Ah6VsYKJPsNIwQAAABNBmmRJqEFsmUwId//+qZYAAJWAAAAADEGegkUVLC//AACygQAAABABnqF0Qr8CH2Vd3cDdvymgAAAAEAGeo2pCvwIelbGCiT7DSMEAAAATQZqoSahBbJlMCHf//qmWAACVgQAAAAxBnsZFFSwv/wAAsoEAAAAQAZ7ldEK/Ah9lXd3A3b8poQAAABABnudqQr8CHpWxgok+w0jAAAAAE0Ga7EmoQWyZTAh3//6plgAAlYAAAAAMQZ8KRRUsL/8AALKBAAAAEAGfKXRCvwIfZV3dwN2/KaAAAAAQAZ8rakK/Ah6VsYKJPsNIwAAAABNBmzBJqEFsmUwId//+qZYAAJWBAAAADEGfTkUVLC//AACygQAAABABn210Qr8CH2Vd3cDdvymhAAAAEAGfb2pCvwIelbGCiT7DSMAAAAATQZt0SahBbJlMCHf//qmWAACVgAAAAAxBn5JFFSwv/wAAsoEAAAAQAZ+xdEK/Ah9lXd3A3b8poAAAABABn7NqQr8CHpWxgok+w0jAAAAAE0GbuEmoQWyZTAh3//6plgAAlYEAAAAMQZ/WRRUsL/8AALKAAAAAEAGf9XRCvwIfZV3dwN2/KaEAAAAQAZ/3akK/Ah6VsYKJPsNIwQAAABNBm/xJqEFsmUwId//+qZYAAJWAAAAADEGeGkUVLC//AACygQAAABABnjl0Qr8CH2Vd3cDdvymgAAAAEAGeO2pCvwIelbGCiT7DSMEAAAATQZogSahBbJlMCHf//qmWAACVgQAAAAxBnl5FFSwv/wAAsoAAAAAQAZ59dEK/Ah9lXd3A3b8poAAAABABnn9qQr8CHpWxgok+w0jBAAAAE0GaZEmoQWyZTAh3//6plgAAlYAAAAAMQZ6CRRUsL/8AALKBAAAAEAGeoXRCvwIfZV3dwN2/KaAAAAAQAZ6jakK/Ah6VsYKJPsNIwQAAABNBmqhJqEFsmUwId//+qZYAAJWBAAAADEGexkUVLC//AACygQAAABABnuV0Qr8CH2Vd3cDdvymhAAAAEAGe52pCvwIelbGCiT7DSMAAAAATQZrsSahBbJlMCHf//qmWAACVgAAAAAxBnwpFFSwv/wAAsoEAAAAQAZ8pdEK/Ah9lXd3A3b8poAAAABABnytqQr8CHpWxgok+w0jAAAAAE0GbMEmoQWyZTAh3//6plgAAlYEAAAAMQZ9ORRUsL/8AALKBAAAAEAGfbXRCvwIfZV3dwN2/KaEAAAAQAZ9vakK/Ah6VsYKJPsNIwAAAABNBm3RJqEFsmUwId//+qZYAAJWAAAAADEGfkkUVLC//AACygQAAABABn7F0Qr8CH2Vd3cDdvymgAAAAEAGfs2pCvwIelbGCiT7DSMAAAAATQZu4SahBbJlMCHf//qmWAACVgQAAAAxBn9ZFFSwv/wAAsoAAAAAQAZ/1dEK/Ah9lXd3A3b8poQAAABABn/dqQr8CHpWxgok+w0jBAAAAE0Gb/EmoQWyZTAh3//6plgAAlYAAAAAMQZ4aRRUsL/8AALKBAAAAEAGeOXRCvwIfZV3dwN2/KaAAAAAQAZ47akK/Ah6VsYKJPsNIwQAAABJBmiBJqEFsmUwIb//+p4QAAScAAAAMQZ5eRRUsL/8AALKAAAAAEAGefXRCvwIfZV3dwN2/KaAAAAAQAZ5/akK/Ah6VsYKJPsNIwQAAABJBmmRJqEFsmUwIb//+p4QAAScAAAAMQZ6CRRUsL/8AALKBAAAAEAGeoXRCvwIfZV3dwN2/KaAAAAAQAZ6jakK/Ah6VsYKJPsNIwQAAABJBmqhJqEFsmUwIX//+jLAABI0AAAAMQZ7GRRUsL/8AALKBAAAAEAGe5XRCvwIfZV3dwN2/KaEAAAAQAZ7nakK/Ah6VsYKJPsNIwAAAABpBmulLqEIQWyRGCCgH8gH9h4AhX/44QAARcAAADGhtb292AAAAbG12aGQAAAAAAAAAAAAAAAAAAAPoAAAfkAABAAABAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAAALknRyYWsAAABcdGtoZAAAAAMAAAAAAAAAAAAAAAEAAAAAAAAfkAAAAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAABEAAAARAAAAAAACRlZHRzAAAAHGVsc3QAAAAAAAAAAQAAH5AAAAQAAAEAAAAACwptZGlhAAAAIG1kaGQAAAAAAAAAAAAAAAAAADIAAAGUAFXEAAAAAAAtaGRscgAAAAAAAAAAdmlkZQAAAAAAAAAAAAAAAFZpZGVvSGFuZGxlcgAAAAq1bWluZgAAABR2bWhkAAAAAQAAAAAAAAAAAAAAJGRpbmYAAAAcZHJlZgAAAAAAAAABAAAADHVybCAAAAABAAAKdXN0YmwAAACVc3RzZAAAAAAAAAABAAAAhWF2YzEAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAABEAEQAEgAAABIAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY//8AAAAvYXZjQwH0AA3/4QAXZ/QADZGbKCIR0IAAAAMAgAAAGQeKFMsBAAVo6+PESAAAABhzdHRzAAAAAAAAAAEAAADKAAACAAAAABRzdHNzAAAAAAAAAAEAAAABAAAGQGN0dHMAAAAAAAAAxgAAAAUAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAEAAAAABxzdHNjAAAAAAAAAAEAAAABAAAAygAAAAEAAAM8c3RzegAAAAAAAAAAAAAAygAABecAAAAZAAAAHAAAAB0AAAAfAAAAGgAAABIAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABYAAAAQAAAAFAAAABQAAAAWAAAAEAAAABQAAAAUAAAAFgAAABAAAAAUAAAAFAAAAB4AAAAUc3RjbwAAAAAAAAABAAAAMAAAAGJ1ZHRhAAAAWm1ldGEAAAAAAAAAIWhkbHIAAAAAAAAAAG1kaXJhcHBsAAAAAAAAAAAAAAAALWlsc3QAAAAlqXRvbwAAAB1kYXRhAAAAAQAAAABMYXZmNTcuODMuMTAw\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMQt89m1jZA1",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__BONUS question__ Use the expert DQN from the previous question to generate some winning games. Train a model that mimicks its behavior. Compare the performances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWq8W1IhjZA1",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irjOljuzjZA2",
        "colab_type": "text"
      },
      "source": [
        "***"
      ]
    }
  ]
}